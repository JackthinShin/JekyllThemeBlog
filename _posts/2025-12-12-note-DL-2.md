---
title: "25秋深度学习训练营-第2周：卷积神经网络"
math: true
categories:
  - Note
tags:
  - 学习记录
  - 深度学习
  - 神经网络
  - 训练营
  - PyTorch
  - Colab
---

# 第2周：卷积神经网络

学习内容：[https://oucai.club/classes/dl/week01#第2周-卷积神经网络](https://oucai.club/classes/dl/week02)

学习视频：[https://www.jianguoyun.com/p/Dde3HS8QrKKIBhi2xpEGIAA](https://www.jianguoyun.com/p/Dde3HS8QrKKIBhi2xpEGIAA)

> 视频学习至1小时06分，包括：
> - CNN的基本结构：卷积、池化、全连接

## 代码练习

### 实验1：MNIST数据集分类

> 构建简单的`CNN`对`mnist`数据集进⾏分类。

#### 第一步： 加载数据 （MNIST）

PyTorch里包含了`MNIST`，`CIFAR10`等常用数据集，调用`torchvision.datasets`即可把这些数据由远程下载到本地，`MNIST`的使用方法如下：

```
torchvision.datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False)

root 为数据集下载到本地后的根目录，包括 training.pt 和 test.pt 文件
train，如果设置为True，从training.pt创建数据集，否则从test.pt创建。
download，如果设置为True, 从互联网下载数据并放到root文件夹下
transform, 一种函数或变换，输入PIL图片，返回变换之后的数据。
target_transform 一种函数或变换，输入目标，进行变换。
```

![Code0](/JekyllThemeBlog/assets/images/DL-2/0.png)

![Code1](/JekyllThemeBlog/assets/images/DL-2/1.png)

![Code2](/JekyllThemeBlog/assets/images/DL-2/2.png)

我们在从远程下载 MNIST 数据时将`shuffle=True`，然而在此处的20张图并没有被打乱顺序。

原因在于这里访问的是：`train_loader.dataset（原始数据集 MNIST）`

而`shuffle`发生在`DataLoader`的`batch`抓取阶段：

![Code3](/JekyllThemeBlog/assets/images/DL-2/3.png)

可以看到数据已经被打乱展示

#### 第二步：创建网络

```
class FC2Layer(nn.Module):
    def __init__(self, input_size, n_hidden, output_size):
        # nn.Module子类的函数必须在构造函数中执行父类的构造函数# 下式等价于nn.Module.__init__(self)        
        super(FC2Layer, self).__init__()
        self.input_size = input_size
        # 这里直接用 Sequential 就定义了网络，注意要和下面 CNN 的代码区分开
        self.network = nn.Sequential(
            nn.Linear(input_size, n_hidden), 
            nn.ReLU(), 
            nn.Linear(n_hidden, n_hidden), 
            nn.ReLU(), 
            nn.Linear(n_hidden, output_size), 
            nn.LogSoftmax(dim=1)
        )

    def forward(self, x):
        # view一般出现在model类的forward函数中，用于改变输入或输出的形状
        # x.view(-1, self.input_size) 的意思是多维的数据展成二维
        # 代码指定二维数据的列数为 input_size=784，行数 -1 表示我们不想算，
        # 电脑会自己计算对应的数字
        # 在 DataLoader 部分，我们可以看到 batch_size 是64，所以得到 x 的行数是64
        # 大家可以加一行代码：print(x.cpu().numpy().shape)
        # 训练过程中，就会看到 (64, 784) 的输出，和我们的预期是一致的
        # forward 函数的作用是，指定网络的运行过程，这个全连接网络可能看不啥意义
        # 下面的CNN网络可以看出 forward 的作用。
        x = x.view(-1, self.input_size)
        return self.network(x)

class CNN(nn.Module):
    def __init__(self, input_size, n_feature, output_size):
        # 执行父类的构造函数，所有的网络都要这么写
        super(CNN, self).__init__()
        # 下面是网络里典型结构的一些定义，一般就是卷积和全连接
        # 池化、ReLU一类的不用在这里定义
        self.n_feature = n_feature
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5)
        self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=5)
        self.fc1 = nn.Linear(n_feature*4*4, 50)
        self.fc2 = nn.Linear(50, 10)    
    
    # 下面的 forward 函数，定义了网络的结构，按照一定顺序，把上面构建的一些结构组织起来
    # 意思就是，conv1, conv2 等等的，可以多次重用
    def forward(self, x, verbose=False):
        x = self.conv1(x)
        x = F.relu(x)
        x = F.max_pool2d(x, kernel_size=2)
        x = self.conv2(x)
        x = F.relu(x)
        x = F.max_pool2d(x, kernel_size=2)
        x = x.view(-1, self.n_feature*4*4)
        x = self.fc1(x)
        x = F.relu(x)
        x = self.fc2(x)
        x = F.log_softmax(x, dim=1)
        return x

# 训练函数
def train(model):
    model.train()
    # 主里从train_loader里，64个样本一个batch为单位提取样本进行训练
    for batch_idx, (data, target) in enumerate(train_loader):
        # 把数据送到GPU中
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        if batch_idx % 100 == 0:
            print('Train: [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                batch_idx * len(data), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), loss.item()))


def test(model):
    model.eval()
    test_loss = 0
    correct = 0
    for data, target in test_loader:
        # 把数据送到GPU中
        data, target = data.to(device), target.to(device)
        # 把数据送入模型，得到预测结果
        output = model(data)
        # 计算本次batch的损失，并加到 test_loss 中
        test_loss += F.nll_loss(output, target, reduction='sum').item()
        # get the index of the max log-probability，最后一层输出10个数
        # 值最大的那个即对应着分类结果，然后把分类结果保存在 pred 里
        pred = output.data.max(1, keepdim=True)[1]
        # 将 pred 与 target 相比，得到正确预测结果的数量，并加到 correct 中
        # 这里需要注意一下 view_as ，意思是把 target 变成维度和 pred 一样的意思                                                
        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()

    test_loss /= len(test_loader.dataset)
    accuracy = 100. * correct / len(test_loader.dataset)
    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        accuracy))
```

#### 第三步：在小型全连接网络上训练（Fully-connected network）

FNN 前馈神经网络(FeedforwardNeural Network)

![Code4](/JekyllThemeBlog//assets/images/DL-2/4.png)

#### 第四步：在卷积神经网络上训练

![Code5](/JekyllThemeBlog//assets/images/DL-2/5.png)

#### 第五步：打乱像素顺序再次在两个网络上训练与测试

考虑到`CNN`在卷积与池化上的优良特性，如果我们把图像中的像素打乱顺序，这样**卷积**和**池化**就难以发挥作用了，为了验证这个想法，我们把图像中的像素打乱顺序再试试。

首先下面代码展示随机打乱像素顺序后，图像的形态：

![Code6](/JekyllThemeBlog//assets/images/DL-2/6.png)

重新定义训练与测试函数，我们写了两个函数 train_perm 和 test_perm，分别对应着加入像素打乱顺序的训练函数与测试函数。

与之前的训练与测试函数基本上完全相同，只是对 data 加入了打乱顺序操作。

```
# 对每个 batch 里的数据，打乱像素顺序的函数
def perm_pixel(data, perm):
    # 转化为二维矩阵
    data_new = data.view(-1, 28*28)
    # 打乱像素顺序
    data_new = data_new[:, perm]
    # 恢复为原来4维的 tensor
    data_new = data_new.view(-1, 1, 28, 28)
    return data_new

# 训练函数
def train_perm(model, perm):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        # 像素打乱顺序
        data = perm_pixel(data, perm)

        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        if batch_idx % 100 == 0:
            print('Train: [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                batch_idx * len(data), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), loss.item()))

# 测试函数
def test_perm(model, perm):
    model.eval()
    test_loss = 0
    correct = 0
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)

        # 像素打乱顺序
        data = perm_pixel(data, perm)

        output = model(data)
        test_loss += F.nll_loss(output, target, reduction='sum').item()
        pred = output.data.max(1, keepdim=True)[1]                                            
        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()

    test_loss /= len(test_loader.dataset)
    accuracy = 100. * correct / len(test_loader.dataset)
    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        accuracy))
```

在全连接网络上训练与测试：

![Code7](/JekyllThemeBlog//assets/images/DL-2/7.png)

在卷积神经网络上训练与测试：

![Code8](/JekyllThemeBlog//assets/images/DL-2/8.png)

从打乱像素顺序的实验结果来看，全连接网络的性能基本上没有发生变化，但是卷积神经网络的性能明显下降。

这是因为对于卷积神经网络，会利用像素的局部关系，但是打乱顺序以后，这些像素间的关系将无法得到利用。

> 分析：
以“一定规律”将图片像素打散的方式测试的可行性在于，对每一张图进行了相同的“不规则改动”，这一改动对于图片内容来说是毁灭性的，但是对于`FNN`来说，被展平(Flatten)的训练集本身的特征只是进行了排序上的改动，规律并没有被打乱，而对于`CNN`来说，由于像素顺序的打乱，使得图片本身“看起来的”信息丢失，卷积及池化过程中完全无法获得任何有用的信息，相较于`FNN`反倒效果变得一般。

## 思考问题：

`dataloader` 里面 `shuffle` 取不同值有什么区别？
`transform` 里，取了不同值，这个有什么区别？
`epoch` 和 `batch` 的区别？
1x1的卷积和 FC 有什么区别？主要起什么作⽤？

## 1. DataLoader 里的 `shuffle` 参数

- **作用**：`shuffle=True`在每个 epoch 开始时打乱数据顺序。避免模型记住数据顺序，增强泛化能力。

## 2. Transform 里取不同值

- **作用**：用于数据预处理和增强（data augmentation）。
- **不同值的影响**：
  - 对训练集：
    - 可以随机裁剪、旋转、翻转、加噪声等 → 增强数据多样性 → 减少过拟合。
  - 对测试集：
    - 通常使用固定的 transform（如 `Resize` + `ToTensor` + `Normalize`） → 保证评估一致性。

## 3. Epoch 和 Batch 的区别

- Epoch（轮次）全部训练集数据被模型完整训练一次，称为一个 epoch。
- Batch（批次）一次送入网络训练的数据量。

## 4. 1x1 卷积 vs 全连接（FC）

1. 经过`1x1 卷积`后的数据仍然拥有空间二维结构，而经过`全连接(FC)`的数据是被展平的，没有了空间信息
2. 1x1 卷积常用于实现压缩深度/维度/通道数(Depth/Channel)

> 一些思考：
既然可以通过打散像素的方式，让（图片）数据的信息不能被CNN较为良好地发现和处理，那么是否可以找到`打散像素`这一过程的逆过程，使得经过此过程，在后续的卷积以及池化过程中，**不直观明显的信息**得以展示？
仔细再想一下，这一番过程似乎同样是一种**特殊的“卷积”**，但是不同于传统矩形的卷积核，如果用卷积核的方式实现这一过程是否会造成效率的降低？
在此之前，值得考虑的是，实际情况中是否真的存在这样的被特定方式**打散**的图片数据？
而除了图片之外，**其他模态**的数据信息是否有这样的特性？
总而言之，疑惑点在于，现在认识到的各类卷积核都是矩形的，且相对较小，重要的特征是否都能被找到？
